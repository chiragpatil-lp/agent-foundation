{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Documentation","text":""},{"location":"#organization","title":"Organization","text":"<p>This directory separates base infrastructure documentation from your custom agent documentation.</p>"},{"location":"#base-infra-base-infrastructure","title":"<code>base-infra/</code> - Base Infrastructure","text":"<p>Base infrastructure documentation. Reference these for deployment, CI/CD, and infrastructure patterns. Do not modify unless contributing back to the template.</p> <p>Contents: - Bootstrap and deployment setup - CI/CD workflows and automation - Docker and development environment - Terraform infrastructure patterns - Observability and production features</p> <p>See base-infra/ for complete list.</p>"},{"location":"#root-your-custom-documentation","title":"Root - Your Custom Documentation","text":"<p>Add your agent-specific documentation here: - Custom tools and capabilities - Domain-specific logic and patterns - Agent instructions and prompts - Integration guides - API documentation</p> <p>Examples: <pre><code>docs/\n\u251c\u2500\u2500 base-infra/              # Base infrastructure (don't modify)\n\u251c\u2500\u2500 custom-tools.md          # Your custom tool documentation\n\u251c\u2500\u2500 domain-guide.md          # Your domain-specific patterns\n\u251c\u2500\u2500 api-integration.md       # Your API integrations\n\u2514\u2500\u2500 agent-instructions.md    # Your agent instruction docs\n</code></pre></p>"},{"location":"#quick-links","title":"Quick Links","text":""},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li>Bootstrap Setup - One-time CI/CD provisioning</li> <li>Development Guide - Local workflow and code quality</li> <li>Environment Variables - Complete configuration reference</li> </ul>"},{"location":"#infrastructure","title":"Infrastructure","text":"<ul> <li>CI/CD Setup - GitHub Actions automation</li> <li>Terraform Infrastructure - IaC setup and patterns</li> <li>Docker Compose Workflow - Local development</li> </ul>"},{"location":"#production","title":"Production","text":"<ul> <li>Observability - Traces and logs</li> <li>Dockerfile Strategy - Build optimization</li> <li>Validating Multi-Platform Builds - Image verification</li> </ul>"},{"location":"base-infra/bootstrap-setup/","title":"Bootstrap Setup","text":"<p>One-time infrastructure provisioning for CI/CD automation.</p> <p>[!NOTE] This is a one-time setup. After successful bootstrap, you won't need to run these commands again unless changing GCP projects or GitHub repositories.</p>"},{"location":"base-infra/bootstrap-setup/#prerequisites","title":"Prerequisites","text":"<ul> <li>Terraform &gt;= 1.14.0</li> <li>Google Cloud SDK (gcloud CLI)</li> <li>GitHub CLI (gh)</li> </ul>"},{"location":"base-infra/bootstrap-setup/#what-bootstrap-creates","title":"What Bootstrap Creates","text":"<ol> <li>Workload Identity Federation - Keyless GitHub Actions authentication</li> <li>Artifact Registry - Docker image storage with cleanup policies</li> <li>Terraform State Bucket - Remote state for main module (GCS)</li> <li>GitHub Variables - Auto-configured repository variables for CI/CD</li> </ol> <p>See Terraform Infrastructure Guide for detailed resource descriptions and IAM roles.</p>"},{"location":"base-infra/bootstrap-setup/#commands","title":"Commands","text":"<p>1. Authenticate: <pre><code>gcloud auth application-default login\ngcloud config set project YOUR_PROJECT_ID\ngh auth login\n</code></pre></p> <p>2. Configure app runtime environment: <pre><code>cp .env.example .env\n# Edit .env with your values (see inline comments)\n</code></pre></p> <p>Required variables in <code>.env</code>: - <code>GOOGLE_CLOUD_PROJECT</code> - <code>GOOGLE_CLOUD_LOCATION</code> - <code>AGENT_NAME</code> - <code>OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT</code></p> <p>3. Configure bootstrap for GitHub: <pre><code>cp terraform/bootstrap/terraform.tfvars.example terraform/bootstrap/terraform.tfvars\n# Edit terraform.tfvars with your GitHub repository info\n</code></pre></p> <p>Required variables in <code>terraform/bootstrap/terraform.tfvars</code>: - <code>repository_owner</code> - GitHub username or organization - <code>repository_name</code> - GitHub repository name</p> <p>4. Initialize Terraform: <pre><code>terraform -chdir=terraform/bootstrap init\n</code></pre></p> <p>5. Preview changes: <pre><code>terraform -chdir=terraform/bootstrap plan\n</code></pre></p> <p>6. Apply: <pre><code>terraform -chdir=terraform/bootstrap apply\n</code></pre></p> <p>Bootstrap typically completes in 2-3 minutes.</p>"},{"location":"base-infra/bootstrap-setup/#verification","title":"Verification","text":"<p>Check GitHub Variables: <pre><code>gh variable list\n</code></pre></p> <p>Expected output: - <code>ARTIFACT_REGISTRY_LOCATION</code> - <code>ARTIFACT_REGISTRY_URI</code> - <code>GCP_LOCATION</code> - <code>GCP_PROJECT_ID</code> - <code>GCP_WORKLOAD_IDENTITY_PROVIDER</code> - <code>IMAGE_NAME</code> - <code>OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT</code> - <code>TERRAFORM_STATE_BUCKET</code></p> <p>View Terraform outputs: <pre><code>terraform -chdir=terraform/bootstrap output\n</code></pre></p>"},{"location":"base-infra/bootstrap-setup/#state-management","title":"State Management","text":"<p>Bootstrap uses local state by default: - State file: <code>terraform/bootstrap/terraform.tfstate</code> (gitignored) - One-time operation, no need for remote state - Team collaboration can optionally configure remote state</p> <p>See Terraform Infrastructure Guide for details.</p>"},{"location":"base-infra/bootstrap-setup/#next-steps","title":"Next Steps","text":"<ol> <li>\u2705 Verify GitHub Variables created</li> <li>\ud83d\udcd6 Continue to Development Guide for feature branch workflow</li> <li>\ud83d\udcd6 See CI/CD Workflow Guide for deployment automation</li> </ol>"},{"location":"base-infra/cicd-setup/","title":"CI/CD Workflow Guide","text":"<p>This guide explains the GitHub Actions workflows that automate building and deploying the LLM agent to Cloud Run.</p>"},{"location":"base-infra/cicd-setup/#overview","title":"Overview","text":"<p>The project uses automated CI/CD via GitHub Actions with four workflows:</p> <ol> <li><code>ci-cd.yml</code> - Orchestrator (meta \u2192 build \u2192 deploy)</li> <li><code>metadata-extract.yml</code> - Reusable metadata extraction</li> <li><code>docker-build.yml</code> - Reusable Docker image build</li> <li><code>terraform-plan-apply.yml</code> - Reusable Terraform deployment</li> </ol> <p>Key principle: Zero manual intervention after initial setup. Merge to main = automatic deployment.</p>"},{"location":"base-infra/cicd-setup/#prerequisites","title":"Prerequisites","text":"<p>Complete one-time bootstrap setup before using CI/CD workflows:</p> <ol> <li>\u2705 Run the Terraform bootstrap module (see Bootstrap Setup)</li> <li>\u2705 Verify GitHub Variables created: <code>gh variable list</code></li> </ol> <p>Bootstrap creates all CI/CD infrastructure: WIF, Artifact Registry, GitHub Variables, Terraform state bucket.</p>"},{"location":"base-infra/cicd-setup/#github-variables-auto-created","title":"GitHub Variables (Auto-Created)","text":"<p>The bootstrap module creates these Variables in your repository:</p> Variable Name Description Created By <code>GCP_PROJECT_ID</code> GCP project ID Bootstrap <code>GCP_LOCATION</code> GCP region Bootstrap <code>IMAGE_NAME</code> Docker image name (also used as agent_name) Bootstrap <code>GCP_WORKLOAD_IDENTITY_PROVIDER</code> WIF provider resource name Bootstrap <code>ARTIFACT_REGISTRY_URI</code> Registry URI Bootstrap <code>ARTIFACT_REGISTRY_LOCATION</code> Registry location Bootstrap <code>TERRAFORM_STATE_BUCKET</code> GCS bucket for main module state Bootstrap <p>Note: These are Variables (not Secrets) because they're resource identifiers, not credentials. Security comes from WIF IAM policies, not obscurity.</p>"},{"location":"base-infra/cicd-setup/#workflow-architecture","title":"Workflow Architecture","text":""},{"location":"base-infra/cicd-setup/#four-workflow-pattern","title":"Four-Workflow Pattern","text":"<pre><code>ci-cd.yml (orchestrator)\n\u251c\u2500\u2500 meta (calls metadata-extract.yml) - Extract metadata and determine tags\n\u251c\u2500\u2500 build (calls docker-build.yml) - Build multi-platform image\n\u2514\u2500\u2500 deploy (calls terraform-plan-apply.yml) - Deploy to Cloud Run\n</code></pre> <p>Benefits: - Clean separation of concerns - Reusable workflows called by orchestrator (no manual triggers) - Direct output passing (no tag reconstruction) - Single orchestrator controls the full pipeline</p>"},{"location":"base-infra/cicd-setup/#workflow-flow","title":"Workflow Flow","text":"<p>On Pull Request: <pre><code>1. metadata-extract.yml extracts: pr-{number}-{sha}\n2. docker-build.yml pushes: registry/image:pr-123-abc123\n3. terraform-plan-apply.yml runs: plan (no apply)\n4. Plan output posted as PR comment\n</code></pre></p> <p>On Push to Main or Version Tag: <pre><code>1. metadata-extract.yml extracts: {sha}, latest, {version} (if tagged)\n2. docker-build.yml pushes: registry/image:abc123 + latest (+ v1.0.0 if tagged)\n3. terraform-plan-apply.yml runs: apply (auto-approved)\n4. Cloud Run service updated with image digest\n</code></pre></p> <p>On Manual Dispatch: <pre><code>1. metadata-extract.yml runs (uses current commit SHA)\n2. docker-build.yml builds image\n3. terraform-plan-apply.yml runs plan or apply (user choice)\n4. Workspace selection: default/dev/stage/prod\n</code></pre></p>"},{"location":"base-infra/cicd-setup/#image-tagging-strategy","title":"Image Tagging Strategy","text":""},{"location":"base-infra/cicd-setup/#pull-request-builds","title":"Pull Request Builds","text":"<p>Format: <code>pr-{number}-{sha}</code> (e.g., <code>pr-123-abc1234</code>) - Unique per commit, isolated from main builds</p>"},{"location":"base-infra/cicd-setup/#main-branch-builds","title":"Main Branch Builds","text":"<p>Tags: <code>{sha}</code> (primary), <code>latest</code>, <code>{version}</code> (if tagged)</p> <p>Example: Commit <code>abc1234</code> tagged <code>v0.9.0</code> produces: <pre><code>registry/image:abc1234  registry/image:latest  registry/image:v0.9.0\n</code></pre></p> <p>Deployment uses image digest (not tags) to ensure every rebuild triggers a new Cloud Run revision.</p>"},{"location":"base-infra/cicd-setup/#version-tag-builds","title":"Version Tag Builds","text":"<p>Trigger: Push git tag matching <code>v*</code> (e.g., <code>git push origin v0.4.0</code>)</p> <p>Automatically builds version-tagged image after release PR is merged. Safe because tags point to already-reviewed code and only authorized users can push tags.</p>"},{"location":"base-infra/cicd-setup/#workflow-behavior","title":"Workflow Behavior","text":"<p>Concurrency: PRs cancel in-progress builds; main runs sequentially. Per-workspace Terraform locking prevents state corruption.</p> <p>Path filtering: Triggers on code/config changes, ignores docs. See <code>.github/workflows/ci-cd.yml</code> for complete path list. Tag triggers (<code>v*</code>) always run.</p> <p>Multi-platform builds: Images built for multiple platforms (see <code>docker-build.yml</code>). Manifest auto-selects architecture.</p> <p>Build cache: Registry cache with protected <code>buildcache</code> tag provides significant speedup on cache hits.</p>"},{"location":"base-infra/cicd-setup/#shell-configuration","title":"Shell Configuration","text":"<p><code>bash {0}</code> pattern: Terraform plan step uses <code>shell: bash {0}</code> to override default <code>bash -e</code> behavior. This allows capturing output on failure for job summaries and PR comments. Default behavior exits immediately on error, preventing output capture. See GitHub Actions workflow syntax.</p>"},{"location":"base-infra/cicd-setup/#pull-request-comments","title":"Pull Request Comments","text":"<p>terraform-plan-apply.yml posts formatted comments showing format/init/validation/plan results with collapsible sections for detailed output.</p>"},{"location":"base-infra/cicd-setup/#job-summaries","title":"Job Summaries","text":"<p>Both the metadata extraction and Terraform deployment jobs generate formatted job summaries visible in the GitHub Actions UI. These summaries provide quick insight into build and deployment status without requiring log analysis.</p> <p>Metadata Extraction Summary includes: - Build context (PR, main branch, tag push, manual) - Branch/tag name and commit SHA - All image tags (formatted as bulleted list)</p> <p>Terraform Deployment Summary includes: - Workspace and action (plan/apply) - Docker image being deployed - Step-by-step outcomes (format, init, validate, plan, apply) - Collapsible plan output (first 50 lines) - Deployed resources (Cloud Run URLs, service account, Agent Engine ID, artifact bucket) for successful applies</p> <p>Job summaries appear at the top of each workflow run, providing a quick overview without navigating through individual job logs.</p>"},{"location":"base-infra/cicd-setup/#workload-identity-federation","title":"Workload Identity Federation","text":"<p>Keyless authentication via WIF: GitHub Actions requests OIDC token, GCP validates against WIF provider, grants temporary credentials scoped to repository.</p> <p>IAM roles: See <code>terraform/bootstrap/main.tf</code> for complete role list.</p>"},{"location":"base-infra/cicd-setup/#testing-workflows","title":"Testing Workflows","text":"<p>Manual trigger via <code>ci-cd.yml</code> orchestrator (also available via GitHub UI: Actions &gt; CI/CD Pipeline &gt; Run workflow):</p> <pre><code># Trigger full pipeline (build + deploy)\ngh workflow run ci-cd.yml \\\n  -f workspace=default \\\n  -f terraform_action=plan\n\n# Verify deployment\ngh run list --workflow=ci-cd.yml --limit 5\ngh run view RUN_ID\ngcloud run services describe IMAGE_NAME --region=us-central1 --format=\"value(status.url)\"\n</code></pre> <p>Note: <code>docker-build.yml</code> and <code>terraform-plan-apply.yml</code> are reusable workflows without manual triggers. Use <code>ci-cd.yml</code> to trigger the full pipeline.</p>"},{"location":"base-infra/cicd-setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"base-infra/cicd-setup/#trace-deployed-image-to-git-commit","title":"Trace Deployed Image to Git Commit","text":"<pre><code># Get commit SHA from deployed image digest\ngcloud artifacts docker images describe \\\n  \"$(gcloud run services describe SERVICE_NAME --region REGION \\\n     --format='value(spec.template.spec.containers[0].image)')\" \\\n  --format=\"value(tags)\" | cut -d',' -f1\n</code></pre>"},{"location":"base-infra/cicd-setup/#missing-variables","title":"Missing Variables","text":"<pre><code>gh variable list  # Verify Variables exist\nterraform -chdir=terraform/bootstrap apply  # Re-run if missing\n</code></pre>"},{"location":"base-infra/cicd-setup/#wif-authentication-failed","title":"WIF Authentication Failed","text":"<pre><code># Check WIF provider\nterraform -chdir=terraform/bootstrap output -raw workload_identity_provider\n\n# Verify IAM bindings\ngcloud projects get-iam-policy PROJECT_ID \\\n  --flatten=\"bindings[].members\" \\\n  --filter=\"bindings.members:principalSet*\"\n</code></pre>"},{"location":"base-infra/cicd-setup/#image-push-denied","title":"Image Push Denied","text":"<pre><code># Verify artifactregistry.writer role\ngcloud projects get-iam-policy PROJECT_ID \\\n  --flatten=\"bindings[].members\" \\\n  --filter=\"bindings.role:roles/artifactregistry.writer\"\n</code></pre>"},{"location":"base-infra/cicd-setup/#pr-comment-not-posted","title":"PR Comment Not Posted","text":"<p>Ensure workflow has <code>pull-requests: write</code> permission.</p>"},{"location":"base-infra/cicd-setup/#build-cache-miss","title":"Build Cache Miss","text":"<p>Builds taking longer than expected? Verify <code>keep-buildcache</code> policy exists in bootstrap module.</p>"},{"location":"base-infra/cicd-setup/#terraform-state-lock","title":"Terraform State Lock","text":"<pre><code>gh run list --workflow=ci-cd.yml --limit 10  # Find stuck runs\ngh run cancel RUN_ID  # Cancel if needed\nterraform -chdir=terraform/main force-unlock LOCK_ID  # Last resort\n</code></pre>"},{"location":"base-infra/cicd-setup/#workflow-timeouts","title":"Workflow Timeouts","text":"<p>Workflows include timeouts to prevent runaway processes. See workflow files for specific values. If timeouts occur frequently, investigate network issues, large build context, or Terraform state locking.</p>"},{"location":"base-infra/cicd-setup/#security-best-practices","title":"Security Best Practices","text":"<ul> <li>Keyless auth via WIF - No service account keys, repository-scoped IAM bindings</li> <li>Minimal permissions - Only required IAM roles, workspace isolation for environments</li> <li>Encrypted state - Remote GCS state with versioning and locking</li> <li>Immutable images - SHA-tagged with cleanup policies, multi-platform manifests</li> </ul>"},{"location":"base-infra/cicd-setup/#next-steps","title":"Next Steps","text":"<ol> <li>\u2705 Complete bootstrap setup (see Terraform Infrastructure Guide)</li> <li>\u2705 Verify GitHub Variables: <code>gh variable list</code></li> <li>\u2705 Test workflow: Create PR, verify plan posted as comment</li> <li>\u2705 Merge PR, verify automatic deployment to Cloud Run</li> <li>\ud83d\udcd6 Monitor deployments: <code>gh run list --workflow=ci-cd.yml</code></li> </ol>"},{"location":"base-infra/cicd-setup/#related-documentation","title":"Related Documentation","text":"<ul> <li>Terraform Infrastructure Guide - Bootstrap and main module setup</li> <li>Validating Multi-Platform Builds - Verify deployed image provenance</li> <li>Development Guide - Local development workflow</li> </ul>"},{"location":"base-infra/development/","title":"Development","text":"<p>This document covers development workflows, code quality standards, and testing.</p>"},{"location":"base-infra/development/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.13+</li> <li><code>uv</code> package manager</li> <li>Google Cloud SDK (gcloud CLI) for Vertex AI authentication</li> </ul> <p>[!NOTE] The agent defaults to in-memory session and artifact services for local development. For production-consistent testing with durable persistence, see Cloud Resource Configuration below.</p>"},{"location":"base-infra/development/#running-locally","title":"Running Locally","text":""},{"location":"base-infra/development/#quick-start-in-memory-mode","title":"Quick Start (In-Memory Mode)","text":"<pre><code># Minimal setup for local development\ncp .env.example .env  # Edit: GOOGLE_CLOUD_PROJECT, GOOGLE_CLOUD_LOCATION\ngcloud auth application-default login\n\n# Run server (uses in-memory sessions/memory/artifacts)\nuv run server  # API-only (set SERVE_WEB_INTERFACE=TRUE for web UI)\nLOG_LEVEL=DEBUG uv run server  # Debug mode\n\n# Docker Compose (recommended - hot reloading)\ndocker compose up --build --watch\n</code></pre> <p>See Docker Compose Workflow and Environment Variables.</p>"},{"location":"base-infra/development/#configure-cloud-resources-optional","title":"Configure Cloud Resources (Optional)","text":"<p>For production-consistent testing with cloud session/memory persistence and GCS artifacts, add deployed resource URIs to <code>.env</code> before running the server:</p> <pre><code># From deployment logs (see CI/CD Infrastructure Setup in README)\nAGENT_ENGINE=projects/.../reasoningEngines/...\nARTIFACT_SERVICE_URI=gs://...\n</code></pre> <p>See Environment Variables for details.</p>"},{"location":"base-infra/development/#testing-deployed-service","title":"Testing Deployed Service","text":"<p>Proxy the deployed Cloud Run service to <code>http://localhost:8000</code> for local testing:</p> <pre><code># Service name format: ${agent_name}-${workspace} (e.g., my-agent-default)\ngcloud run services proxy &lt;service-name&gt; --project &lt;project-id&gt; --region &lt;region&gt; --port 8000\n\n# Example\ngcloud run services proxy my-agent-default --project my-project-id --region us-central1 --port 8000\ncurl http://localhost:8000/health\n\n# Use a different port if 8000 is in use\ngcloud run services proxy &lt;service-name&gt; --project &lt;project-id&gt; --region &lt;region&gt; --port 8080\n\n# Stop proxy: Ctrl+C\n</code></pre> <p>If <code>SERVE_WEB_INTERFACE=TRUE</code> is set in the deployed service, open http://localhost:8000 in your browser to access the web UI.</p> <p>Uses active gcloud account credentials (<code>gcloud auth login</code>).</p> <p>See Cloud Run proxy documentation for details.</p>"},{"location":"base-infra/development/#development-workflow","title":"Development Workflow","text":""},{"location":"base-infra/development/#feature-branch-development","title":"Feature Branch Development","text":"<pre><code># Create branch (feat/, fix/, docs/, refactor/, test/)\ngit checkout -b feat/your-feature-name\n\n# Develop locally\nuv run server  # Fast iteration\n# Or: docker compose up --build --watch  # Matches production\n\n# Quality checks before commit (100% coverage required)\nuv run ruff format &amp;&amp; uv run ruff check &amp;&amp; uv run mypy\nuv run pytest --cov --cov-report=term-missing\n\n# Commit (conventional format: 50 char title, list body)\ngit add . &amp;&amp; git commit -m \"feat: add new tool\"\n</code></pre>"},{"location":"base-infra/development/#pull-request-and-deployment","title":"Pull Request and Deployment","text":"<pre><code># Push and create PR\ngit push origin feat/your-feature-name\ngh pr create  # Follow PR format: What, Why, How, Tests\n\n# After merge to main, monitor deployment\ngh run list --workflow=ci-cd.yml --limit 5\ngh run view --log\n</code></pre> <p>GitHub Actions automatically builds, tests, and deploys to Cloud Run. Check job summary for deployment details.</p>"},{"location":"base-infra/development/#cloud-resource-configuration","title":"Cloud Resource Configuration","text":"<p>After deploying infrastructure (see README), capture resource values for local development.</p> <p>Get values from GitHub Actions logs (<code>gh run view &lt;run-id&gt;</code> or Actions tab UI) or GCP Console:</p> <pre><code># Add to .env:\nAGENT_ENGINE=projects/PROJECT_ID/locations/LOCATION/reasoningEngines/ID\nARTIFACT_SERVICE_URI=gs://BUCKET_NAME\n</code></pre> <p>See Environment Variables for where to find each value.</p>"},{"location":"base-infra/development/#code-quality-and-testing","title":"Code Quality and Testing","text":"<pre><code># Quality checks (run before commit)\nuv run ruff format &amp;&amp; uv run ruff check &amp;&amp; uv run mypy\n\n# Tests (100% coverage required)\nuv run pytest --cov --cov-report=term-missing\n\n# Specific tests\nuv run pytest tests/test_integration.py -v\nuv run pytest tests/test_file.py::test_name -v\n</code></pre>"},{"location":"base-infra/development/#standards","title":"Standards","text":"<p>Type Hints: Strict mypy, complete annotations, modern Python 3.13+ syntax (<code>|</code> unions, lowercase generics), Pydantic validation.</p> <p>Code Style: Ruff (88-char lines, auto-fix). Always use <code>Path</code> objects (never <code>os.path</code>). See <code>pyproject.toml</code> for rules.</p> <p>Docstrings: Google-style format. Document args, returns, exceptions.</p> <p>Testing: 100% coverage (excludes server.py, agent.py, scripts). Shared fixtures in <code>conftest.py</code>. Duck-typed mocks.</p>"},{"location":"base-infra/development/#dependencies","title":"Dependencies","text":"<p>Runtime: Google ADK, pydantic, python-dotenv Dev: pytest, ruff, mypy (PEP 735 <code>dev</code> group, auto-installed with <code>uv run</code>)</p> <pre><code>uv add package-name              # Add runtime dependency\nuv add --group dev package-name  # Add dev dependency\nuv lock --upgrade                # Update all\nuv lock --upgrade-package pkg    # Update specific\n</code></pre>"},{"location":"base-infra/development/#project-structure","title":"Project Structure","text":"<pre><code>your-agent-name/\n  src/your_agent_name/\n    agent.py              # LlmAgent configuration\n    callbacks.py          # Agent callbacks\n    prompt.py             # Agent prompts\n    tools.py              # Custom tools\n    server.py             # FastAPI development server\n    utils/                # Utilities\n      config.py           # Configuration and environment parsing\n      observability.py    # OpenTelemetry setup\n  tests/                  # Test suite\n    conftest.py           # Shared fixtures\n    test_*.py             # Unit and integration tests\n  terraform/              # Infrastructure as code\n    bootstrap/            # One-time CI/CD setup\n    main/                 # Cloud Run deployment\n  docs/                   # Documentation\n  notebooks/              # Jupyter notebooks\n  .env.example            # Environment template\n  pyproject.toml          # Project configuration\n  docker-compose.yml      # Local development\n  Dockerfile              # Container image\n  CLAUDE.md               # Project instructions\n  README.md               # Main documentation\n</code></pre>"},{"location":"base-infra/development/#observability","title":"Observability","text":"<p>OpenTelemetry exports traces to Cloud Trace and logs to Cloud Logging. Control log level: <code>LOG_LEVEL=DEBUG uv run server</code></p> <p>View traces/logs: - Cloud Trace | Logs Explorer - CLI: <code>gcloud logging tail \"logName:projects/{PROJECT_ID}/logs/{AGENT_NAME}-otel-logs\"</code></p> <p>See Observability Guide for details.</p>"},{"location":"base-infra/docker-compose-workflow/","title":"Docker Compose Local Development Workflow","text":"<p>This guide covers the recommended workflow for local development using Docker Compose.</p>"},{"location":"base-infra/docker-compose-workflow/#quick-start","title":"Quick Start","text":""},{"location":"base-infra/docker-compose-workflow/#daily-development-recommended","title":"Daily Development (Recommended)","text":"<pre><code>docker compose up --build --watch\n</code></pre> <p>Why both flags? - <code>--build</code>: Ensures you have the latest code and dependencies - <code>--watch</code>: Enables hot reloading for instant feedback</p> <p>What happens: - Container starts with your latest code - Watch mode monitors your files for changes - Edits to <code>src/</code> files are synced instantly (no rebuild needed) - Changes to <code>pyproject.toml</code> or <code>uv.lock</code> trigger automatic rebuild</p> <p>Leave it running while you develop - changes are applied automatically!</p>"},{"location":"base-infra/docker-compose-workflow/#common-commands","title":"Common Commands","text":""},{"location":"base-infra/docker-compose-workflow/#start-with-hot-reloading-default-workflow","title":"Start with hot reloading (default workflow)","text":"<pre><code>docker compose up --build --watch\n</code></pre>"},{"location":"base-infra/docker-compose-workflow/#stop-the-service","title":"Stop the service","text":"<pre><code># Press Ctrl+C to gracefully stop\n# Or in another terminal:\ndocker compose down\n</code></pre>"},{"location":"base-infra/docker-compose-workflow/#view-logs","title":"View logs","text":"<pre><code># If running in detached mode\ndocker compose logs -f\n\n# View just the app logs\ndocker compose logs -f app\n</code></pre>"},{"location":"base-infra/docker-compose-workflow/#rebuild-without-starting","title":"Rebuild without starting","text":"<pre><code>docker compose build\n</code></pre>"},{"location":"base-infra/docker-compose-workflow/#run-without-watch-mode","title":"Run without watch mode","text":"<pre><code>docker compose up --build\n</code></pre>"},{"location":"base-infra/docker-compose-workflow/#how-watch-mode-works","title":"How Watch Mode Works","text":"<p>Watch mode uses the configuration in <code>docker-compose.yml</code>:</p> <pre><code>develop:\n  watch:\n    # Sync: Instant file copy, no rebuild\n    - action: sync\n      path: ./src\n      target: /app/src\n\n    # Rebuild: Triggers full image rebuild\n    - action: rebuild\n      path: ./pyproject.toml\n\n    - action: rebuild\n      path: ./uv.lock\n</code></pre>"},{"location":"base-infra/docker-compose-workflow/#sync-action","title":"Sync Action","text":"<ul> <li>Triggers when: You edit files in <code>src/</code></li> <li>What happens: Files are copied into running container instantly</li> <li>Speed: Immediate (no rebuild)</li> <li>Use case: Code changes during development</li> </ul>"},{"location":"base-infra/docker-compose-workflow/#rebuild-action","title":"Rebuild Action","text":"<ul> <li>Triggers when: You edit <code>pyproject.toml</code> or <code>uv.lock</code></li> <li>What happens: Full image rebuild, container recreated</li> <li>Speed: ~5-10 seconds (with cache)</li> <li>Use case: Dependency changes</li> </ul>"},{"location":"base-infra/docker-compose-workflow/#file-locations","title":"File Locations","text":""},{"location":"base-infra/docker-compose-workflow/#source-code","title":"Source Code","text":"<ul> <li>Host: <code>./src/</code></li> <li>Container: <code>/app/src</code></li> <li>Sync: Automatic via watch mode</li> </ul>"},{"location":"base-infra/docker-compose-workflow/#data-directory","title":"Data Directory","text":"<ul> <li>Host: <code>./data/</code></li> <li>Container: <code>/app/data</code> (read-only)</li> <li>Purpose: Optional data files for agent</li> </ul>"},{"location":"base-infra/docker-compose-workflow/#environment-variables","title":"Environment Variables","text":"<p>Docker Compose loads <code>.env</code> automatically. Key variables:</p> <pre><code># Google Cloud Vertex AI model authentication\nGOOGLE_GENAI_USE_VERTEXAI=TRUE\nGOOGLE_CLOUD_PROJECT=your-project-id\nGOOGLE_CLOUD_LOCATION=us-central1\n\n# Logging verbosity\nLOG_LEVEL=DEBUG\n\n# Server configuration\n# **RECOMMENDED**: DO NOT OVERRIDE PORT here when running with docker-compose\n# Dockerfile overrides HOST=0.0.0.0 in container\n# docker-compose maps container port 8000 to 8000 on the host machine\n\n# Enable web UI\nSERVE_WEB_INTERFACE=true\n\n# Additional variables as needed...\n</code></pre> <p>Note: The container uses <code>HOST=0.0.0.0</code> to allow connections from the host machine.</p>"},{"location":"base-infra/docker-compose-workflow/#troubleshooting","title":"Troubleshooting","text":""},{"location":"base-infra/docker-compose-workflow/#container-keeps-restarting","title":"Container keeps restarting","text":"<ul> <li>Check logs: <code>docker compose logs -f</code></li> <li>Verify <code>.env</code> file exists and has required variables</li> <li>Ensure Application Default Credentials are configured: <code>gcloud auth application-default login</code></li> </ul>"},{"location":"base-infra/docker-compose-workflow/#changes-not-appearing","title":"Changes not appearing","text":"<ul> <li>For code changes: Should sync instantly via watch mode</li> <li>For dependency changes: Watch should auto-rebuild</li> <li>If stuck: Stop and restart with <code>docker compose up --build --watch</code></li> </ul>"},{"location":"base-infra/docker-compose-workflow/#permission-errors","title":"Permission errors","text":"<ul> <li>Data directory: Mounted read-only, should not need write access</li> <li>Credentials: Ensure <code>~/.config/gcloud/application_default_credentials.json</code> exists and is readable</li> </ul>"},{"location":"base-infra/docker-compose-workflow/#port-already-in-use","title":"Port already in use","text":"<pre><code># Check what's using port 8000\nlsof -i :8000\n\n# Stop the conflicting process or change PORT in .env\nPORT=8001\n</code></pre>"},{"location":"base-infra/docker-compose-workflow/#windows-path-compatibility","title":"Windows path compatibility","text":"<ul> <li>The <code>docker-compose.yml</code> uses <code>${HOME}</code> which is Unix/Mac specific</li> <li>Windows users need to update the volume path in <code>docker-compose.yml</code>:</li> <li>Replace <code>${HOME}/.config/gcloud/application_default_credentials.json</code></li> <li>With your Windows path: <code>C:\\Users\\YourUsername\\AppData\\Roaming\\gcloud\\application_default_credentials.json</code></li> <li>Alternative: Use <code>%USERPROFILE%</code> environment variable in PowerShell</li> <li>See the comment in <code>docker-compose.yml</code> for the exact syntax</li> </ul>"},{"location":"base-infra/docker-compose-workflow/#testing-registry-images-locally","title":"Testing Registry Images Locally","text":"<p>Test the exact container image built by CI/CD without rebuilding locally.</p> <p>One-time setup: <pre><code># Authenticate to your container registry\n# For GCP Artifact Registry:\ngcloud auth configure-docker &lt;registry-location&gt;-docker.pkg.dev\n\n# For other registries:\n# AWS ECR: aws ecr get-login-password --region &lt;region&gt; | docker login --username AWS --password-stdin &lt;account-id&gt;.dkr.ecr.&lt;region&gt;.amazonaws.com\n# Docker Hub: docker login\n</code></pre></p> <p>Pull and run: <pre><code># Set your full image name\nexport REGISTRY_IMAGE=\"&lt;location&gt;-docker.pkg.dev/&lt;project-id&gt;/&lt;repository&gt;/&lt;image-name&gt;:latest\"\n\n# Pull the image (explicit pull required for multi-platform image behavior with docker-compose)\ndocker pull $REGISTRY_IMAGE\n\n# Run the image using docker-compose with registry override\ndocker compose -f docker-compose.yml -f docker-compose.registry.yml up\n</code></pre></p> <p>This tests the exact artifact from your CI/CD pipeline. The container runs with a <code>-registry</code> suffix (e.g., <code>app-registry</code>) to make it easy to distinguish registry-pulled images from those locally-built.</p> <p>Note on multi-platform images: The <code>docker images</code> command displays manifest list metadata rather than platform-specific image metadata for multi-platform images pulled from registries. You may see an epoch timestamp (1970-01-01) and manifest size (~43MB) instead of the actual image details. This is expected Docker behavior - the real platform-specific image (~171MB) is fully pulled and functional. Use <code>docker inspect &lt;image&gt;</code> to view actual image metadata, or simply run the container to verify it works correctly.</p>"},{"location":"base-infra/docker-compose-workflow/#direct-docker-commands-without-compose","title":"Direct Docker Commands (Without Compose)","text":"<p>If you need to build and run without docker-compose:</p> <pre><code># Build the image with BuildKit\nDOCKER_BUILDKIT=1 docker build -t your-agent-name:latest .\n\n# Run directly\ndocker run \\\n  -v ./data:/app/data:ro \\\n  -p 127.0.0.1:8000:8000 \\\n  --env-file .env \\\n  your-agent-name:latest\n</code></pre> <p>Note: Docker Compose is recommended - it handles volumes, environment, and networking automatically.</p>"},{"location":"base-infra/docker-compose-workflow/#references","title":"References","text":"<ul> <li>Docker Compose Documentation</li> <li>Docker Compose Watch Mode</li> <li>Dockerfile Strategy Guide - Architecture decisions and design rationale</li> </ul>"},{"location":"base-infra/dockerfile-strategy/","title":"Dockerfile Strategy Explained","text":"<p>This document explains our multi-stage Docker build strategy and why we chose this approach for containerizing the agent.</p>"},{"location":"base-infra/dockerfile-strategy/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Overview</li> <li>Dockerfile Breakdown</li> <li>Why Not Use UV Image Directly</li> <li>Performance Comparison</li> <li>Summary</li> </ul>"},{"location":"base-infra/dockerfile-strategy/#overview","title":"Overview","text":"<p>Our Dockerfile uses a multi-stage build with the following architecture:</p> <ol> <li>Builder Stage: <code>python:3.13-slim</code> + uv binary (copied from Astral's distroless image)</li> <li>Runtime Stage: Clean <code>python:3.13-slim</code> + only the virtual environment</li> </ol> <p>This approach gives us: - \u2705 Official uv binary (always latest) - \u2705 Full build capabilities (shell, Python, package manager) - \u2705 Minimal runtime image (~200MB vs ~500MB) - \u2705 Fast rebuilds (5-10s for code changes) - \u2705 Maximum security (non-root, minimal attack surface)</p>"},{"location":"base-infra/dockerfile-strategy/#dockerfile-breakdown","title":"Dockerfile Breakdown","text":""},{"location":"base-infra/dockerfile-strategy/#buildkit-directive","title":"BuildKit Directive","text":"<p><pre><code># syntax=docker/dockerfile:1\n</code></pre> What: Tells Docker to use BuildKit parser (modern Docker build engine) Why: Enables advanced features like <code>--mount=type=cache</code> and parallel builds</p>"},{"location":"base-infra/dockerfile-strategy/#builder-stage-base-image","title":"Builder Stage Base Image","text":"<p><pre><code>FROM python:3.13-slim AS builder\n</code></pre> What: Start builder stage with official Python 3.13 slim image (Debian-based) Why: We need: - Python runtime for <code>uv sync</code> to work - Shell and basic utilities (cp, mkdir, etc.) for build commands</p> <p>Why not <code>ghcr.io/astral-sh/uv:latest</code> as base? - Astral's uv image is distroless (no shell, no package manager) - You can't run <code>RUN</code> commands in distroless images - It's designed to copy the binary FROM, not build FROM</p>"},{"location":"base-infra/dockerfile-strategy/#copy-uv-binary","title":"Copy UV Binary","text":"<p><pre><code>COPY --from=ghcr.io/astral-sh/uv:latest /uv /uvx /bin/\n</code></pre> What: Extract just the <code>uv</code> and <code>uvx</code> binaries from Astral's image Why: - Gets latest uv version without manually tracking releases - Copies only ~10MB of binaries (not a whole base image) - Puts them in <code>/bin/</code> so they're in PATH</p> <p>Key insight: We get official uv without the distroless constraints.</p>"},{"location":"base-infra/dockerfile-strategy/#working-directory-builder-stage","title":"Working Directory (Builder Stage)","text":"<p><pre><code>WORKDIR /app\n</code></pre> What: Set working directory to <code>/app</code> Why: - All subsequent commands run from this directory - Creates the directory if it doesn't exist - Standard convention for application code</p>"},{"location":"base-infra/dockerfile-strategy/#uv-environment-variables","title":"UV Environment Variables","text":"<p><pre><code>ENV UV_LINK_MODE=copy \\\n    UV_COMPILE_BYTECODE=1 \\\n    UV_PYTHON_DOWNLOADS=never\n</code></pre> What: Configure uv behavior Why:</p> Variable Value Reason <code>UV_LINK_MODE=copy</code> Copy files instead of hardlinking Safer for Docker layers, works across filesystems <code>UV_COMPILE_BYTECODE=1</code> Pre-compile .py \u2192 .pyc files Faster startup (no compilation at runtime) <code>UV_PYTHON_DOWNLOADS=never</code> Don't download Python Use system Python from base image"},{"location":"base-infra/dockerfile-strategy/#install-dependencies","title":"Install Dependencies","text":"<p><pre><code># Copy dependency files - explicit cache invalidation when either file changes\nCOPY pyproject.toml uv.lock ./\n\n# Install dependencies (cache mount provides the performance optimization)\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    uv sync --locked --no-install-project --no-dev\n</code></pre> What: Install dependencies WITHOUT installing the project itself Why: Key optimization strategy</p> Flag Meaning Benefit <code>--mount=type=cache</code> Persist <code>/root/.cache/uv</code> across builds Don't re-download packages if already cached (~80% speedup) <code>--locked</code> Validate lockfile matches pyproject.toml Catches mistakes, prevents silent failures (our standard) <code>--no-install-project</code> Skip installing <code>src/may_package</code> Separates dependencies (slow) from code (fast) <code>--no-dev</code> Skip dev dependencies Smaller image <p>Why COPY both files? - \u2705 Explicit cache invalidation - When dependencies change, this layer rebuilds (as it should) - \u2705 Predictable - Standard Docker caching behavior, no surprises - \u2705 Simple - Easy to understand and maintain - \u2705 Fast anyway - Cache mount makes rebuilds quick (~2-5s even on version bumps)</p> <p>Why <code>--locked</code> (not <code>--frozen</code>)?</p> <p>We standardize on <code>--locked</code> for all builds. Here's why:</p> Flag Behavior When to Use <code>--locked</code> Validates lockfile matches pyproject.toml \u2705 Always (our standard) <code>--frozen</code> Skips validation, silently uses stale lockfile \u274c Avoid <p>Why avoid <code>--frozen</code>: - \u274c Silently installs wrong dependencies if lockfile is stale - \u274c Even UV's official CI/CD examples use <code>--locked</code> - \u274c Hides developer mistakes instead of catching them</p> <p>Why use <code>--locked</code> everywhere: - \u2705 Catches developer mistakes (forgot to run <code>uv lock</code>) - \u2705 Ensures lockfile and pyproject.toml stay synchronized - \u2705 Fails fast with clear error message - \u2705 Validation is negligible cost (~milliseconds) - \u2705 Enforces correct workflow: change deps \u2192 <code>uv lock</code> \u2192 commit both files</p> <p>Example of <code>--locked</code> preventing bugs: <pre><code># Developer adds pandas to pyproject.toml but forgets to run uv lock\n$ docker build .\nERROR: The lockfile is out of sync with pyproject.toml\n# Developer: \"Oh right, I need to run uv lock first!\"\n$ uv lock\n$ docker build .  # Now succeeds with correct dependencies\n</code></pre></p> <p>Bottom line: We use <code>--locked</code> in development, CI/CD, and production. We'll only consider <code>--frozen</code> if we encounter a very specific use case that requires skipping validation (none identified yet).</p> <p>Cache mount is the real optimization - It persists across builds, so even \"unnecessary\" rebuilds are fast.</p>"},{"location":"base-infra/dockerfile-strategy/#copy-source-code","title":"Copy Source Code","text":"<p><pre><code># Copy only source code (documentation changes won't invalidate this layer)\nCOPY src ./src\n</code></pre> What: Copy only the application source code Why: - Done AFTER dependencies to maximize cache hits - Optimization: Only copies source code, not documentation (README.md) - Documentation updates won't invalidate this layer or trigger project reinstall - Code changes trigger rebuild as expected - This layer rebuilds only on source code changes (~5-10s) - More targeted than <code>COPY . /app</code> - avoids redundant pyproject.toml/uv.lock copy</p>"},{"location":"base-infra/dockerfile-strategy/#install-project","title":"Install Project","text":"<p><pre><code># Install project itself (create empty README to satisfy package metadata requirements)\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    touch README.md &amp;&amp; \\\n    uv sync --locked --no-editable --no-dev\n</code></pre> What: Install the project itself (now that source code exists) Why: - <code>touch README.md</code>: Creates empty README to satisfy package metadata requirements   - Performance optimization: README changes won't trigger this layer rebuild   - Only source code changes (<code>src/</code>) invalidate this layer   - Intentional trade-off: runtime container won't have real README (not needed for execution) - <code>--locked</code>: Validates lockfile matches pyproject.toml (catches mistakes) - <code>--no-editable</code>: Install as a regular package (not editable/develop mode) - Reuses dependencies from previous step (already in .venv) - Fast because dependencies already installed (~5-10s)</p>"},{"location":"base-infra/dockerfile-strategy/#runtime-stage-base","title":"Runtime Stage Base","text":"<p><pre><code>FROM python:3.13-slim AS runtime\n</code></pre> What: Start fresh with clean Python image for runtime Why: Multi-stage build benefits: - Builder stage has uv, build tools, cache \u2192 ~500MB - Runtime stage only has Python and your .venv \u2192 ~200MB - 50%+ size reduction by discarding build tools</p>"},{"location":"base-infra/dockerfile-strategy/#non-root-user","title":"Non-Root User","text":"<p><pre><code>RUN groupadd -r app &amp;&amp; useradd -r -g app app\n</code></pre> What: Create a non-root system user named <code>app</code> Why: Security best practice - Containers shouldn't run as root - Limits damage if container is compromised - Standard container orchestration pattern</p> <p>Command breakdown: - <code>groupadd -r app</code>: Create system group (<code>-r</code> assigns GID &lt; 1000 automatically) - <code>useradd -r -g app app</code>: Create system user (<code>-r</code> assigns UID &lt; 1000, <code>-g app</code> assigns to group) - No home directory created, shell defaults to <code>/usr/sbin/nologin</code> (prevents login)</p> <p>Alternative approach: Some Dockerfiles use explicit UIDs (e.g., <code>useradd -u 1001 -g appgroup -m -d /app</code>) for traditional volume sharing (NFS, Docker volumes). We use system users (<code>-r</code>) because: - GCS fuse authentication uses service account IAM, not file UIDs - Simpler - fewer flags, system assigns non-conflicting IDs - No home directory needed - app doesn't write to <code>~/</code></p> <p>For traditional shared volumes with POSIX permissions, explicit UIDs are needed. For object storage (GCS), system users are sufficient.</p> <p>Reference: Depot.dev Python UV Dockerfile shows explicit UID approach</p>"},{"location":"base-infra/dockerfile-strategy/#working-directory-runtime-stage","title":"Working Directory (Runtime Stage)","text":"<p><pre><code>WORKDIR /app\n</code></pre> What: Set working directory again (new stage = new filesystem) Why: Container starts in <code>/app</code> when it runs</p>"},{"location":"base-infra/dockerfile-strategy/#copy-application-from-builder","title":"Copy Application from Builder","text":"<p><pre><code>COPY --from=builder --chown=app:app /app .\n</code></pre> What: Copy entire application directory from builder stage Why: - <code>--from=builder</code>: Get everything from builder's <code>/app</code> - <code>--chown=app:app</code>: Make the <code>app</code> user own it - Destination <code>.</code> uses WORKDIR context (copies to <code>/app</code>) - Includes <code>.venv/</code> (all dependencies + installed package) - Includes <code>src/</code> (application code) - Includes metadata (pyproject.toml, uv.lock, README.md) - Simple, conventional pattern - one COPY instead of multiple - Metadata files are tiny (~30 KB) and harmless - uv is NOT copied (only in builder stage, not needed at runtime)</p>"},{"location":"base-infra/dockerfile-strategy/#runtime-environment","title":"Runtime Environment","text":"<p><pre><code>ENV VIRTUAL_ENV=/app/.venv \\\n    PATH=\"/app/.venv/bin:$PATH\" \\\n    PYTHONUNBUFFERED=1 \\\n    AGENT_DIR=/app/src \\\n    HOST=0.0.0.0 \\\n    PORT=8000\n</code></pre> What: Configure runtime environment Why:</p> Variable Purpose <code>VIRTUAL_ENV=/app/.venv</code> Tell Python which venv to use <code>PATH=\"/app/.venv/bin:$PATH\"</code> Make venv binaries available (python, uvicorn) <code>PYTHONUNBUFFERED=1</code> Don't buffer stdout/stderr (better logs in Docker) <code>HOST=0.0.0.0</code> Explicitly bind all interfaces for containers (server.py defaults to 127.0.0.1) <code>PORT=8000</code> Explicitly set default port (matches EXPOSE and server.py default) <code>AGENT_DIR=/app/src</code> Override agent directory path (see AGENT_DIR section below)"},{"location":"base-infra/dockerfile-strategy/#agent_dir-configuration","title":"AGENT_DIR Configuration","text":"<p>The Problem:</p> <p>When the package is installed in non-editable mode (Docker), the source code is copied to the virtual environment's site-packages: - Local (editable): <code>Path(__file__)</code> \u2192 <code>/path/to/project/src/your_agent_name/server.py</code> - Docker (non-editable): <code>Path(__file__)</code> \u2192 <code>/app/.venv/lib/python3.13/site-packages/your_agent_name/server.py</code></p> <p>Using <code>Path(__file__).parent.parent</code> for <code>AGENT_DIR</code>: - Local: Resolves to <code>/path/to/project/src/</code> \u2705 Correct (contains only your_agent_name/) - Docker: Resolves to <code>/app/.venv/lib/python3.13/site-packages/</code> \u274c Wrong (contains all packages)</p> <p>This causes the ADK web UI to show all installed packages (.dist-info directories) instead of just our agent.</p> <p>The Solution:</p> <pre><code># In server.py - configurable with smart default\nAGENT_DIR = os.getenv(\"AGENT_DIR\", str(Path(__file__).parent.parent))\n</code></pre> <pre><code># In Dockerfile - override for Docker environment\nENV AGENT_DIR=/app/src\n</code></pre> <p>Why this works: - Local dev: No <code>AGENT_DIR</code> env var \u2192 uses <code>Path(__file__).parent.parent</code> \u2192 <code>/path/to/project/src/</code> \u2705 - Docker: <code>AGENT_DIR=/app/src</code> env var set \u2192 overrides default \u2192 <code>/app/src/</code> \u2705 - Both point to directory containing only the agent source code - Configurable via environment variable for other deployment scenarios</p>"},{"location":"base-infra/dockerfile-strategy/#switch-to-non-root","title":"Switch to Non-Root","text":"<p><pre><code>USER app\n</code></pre> What: All subsequent commands run as <code>app</code> user Why: - Container starts as <code>app</code> user at runtime - Can't escalate to root - Security best practice</p>"},{"location":"base-infra/dockerfile-strategy/#expose-port","title":"Expose Port","text":"<p><pre><code>EXPOSE 8000\n</code></pre> What: Document that container listens on port 8000 Why: - Documentation only (doesn't actually publish port) - Tools like docker-compose read this for defaults - Good practice for clarity</p>"},{"location":"base-infra/dockerfile-strategy/#startup-command","title":"Startup Command","text":"<p><pre><code># Run the FastAPI server via main() for unified startup logic (logging, etc.)\nCMD [\"python\", \"-m\", \"your_agent_name.server\"]\n</code></pre> What: Default command when container starts Why: - Calls <code>server.main()</code> for unified startup logic   - Sets up OpenTelemetry observability (traces and logs to Google Cloud)   - Consistent entry point for both local dev (<code>uv run server</code>) and Docker - <code>main()</code> calls <code>uvicorn.run(app, host=os.getenv(\"HOST\", \"127.0.0.1\"), port=...)</code>   - Secure default: 127.0.0.1 (only local connections)   - Dockerfile sets <code>HOST=0.0.0.0</code> to explicitly bind all interfaces for containers   - Respects HOST and PORT environment variables for flexibility - JSON array format (exec form, not shell form) \u2192 more efficient - Can be overridden at runtime</p>"},{"location":"base-infra/dockerfile-strategy/#why-not-use-uv-image-directly","title":"Why Not Use UV Image Directly?","text":"<p>Let's compare the approaches:</p>"},{"location":"base-infra/dockerfile-strategy/#using-uv-image-directly-wont-work","title":"\u274c Using UV Image Directly (Won't Work)","text":"<pre><code>FROM ghcr.io/astral-sh/uv:latest\n\n# ERROR: No shell to run these commands!\nRUN uv sync  # FAILS - distroless has no /bin/sh\nCOPY src ./src  # Works, but then what?\n</code></pre> <p>Problems: - Distroless = no shell \u2192 can't run <code>RUN</code> commands - No package manager \u2192 can't install system dependencies if needed - Image is ~100MB but you can't build anything with it - Designed for copying FROM, not building FROM</p>"},{"location":"base-infra/dockerfile-strategy/#our-approach-multi-stage","title":"\u2705 Our Approach (Multi-Stage)","text":"<pre><code># Builder: Use python:3.13-slim + uv binary\nFROM python:3.13-slim AS builder\nCOPY --from=ghcr.io/astral-sh/uv:latest /uv /bin/\n# ... build with full shell/utilities ...\n\n# Runtime: Clean python:3.13-slim + only .venv\nFROM python:3.13-slim AS runtime\nCOPY --from=builder /app/.venv /app/.venv\n</code></pre> <p>Benefits: - Builder has shell + Python + uv \u2192 can build anything - Runtime is minimal \u2192 small image size - Gets official uv binary \u2192 always latest - Best of both worlds</p>"},{"location":"base-infra/dockerfile-strategy/#why-we-copy-instead-of-using-bind-mounts","title":"Why We COPY Instead of Using Bind Mounts","text":""},{"location":"base-infra/dockerfile-strategy/#the-question-should-we-optimize-further","title":"The Question: Should We Optimize Further?","text":"<p>You might wonder: \"Why not use bind mounts to avoid copying dependency files into layers?\"</p> <p>UV's documentation shows bind mount examples, but we deliberately chose the simpler COPY approach. Here's why:</p>"},{"location":"base-infra/dockerfile-strategy/#copy-approach-what-we-use","title":"COPY Approach (What We Use)","text":"<pre><code>COPY pyproject.toml uv.lock ./\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    uv sync --locked --no-install-project\n</code></pre> <p>What happens: - Both files copied into builder layer - Docker tracks both files for cache invalidation - When either file changes, layer rebuilds - Cache mount makes rebuilds fast (~2-5s)</p>"},{"location":"base-infra/dockerfile-strategy/#bind-mount-alternative-what-we-dont-use","title":"Bind Mount Alternative (What We Don't Use)","text":"<pre><code>RUN --mount=type=cache,target=/root/.cache/uv \\\n    --mount=type=bind,source=pyproject.toml,target=pyproject.toml \\\n    --mount=type=bind,source=uv.lock,target=uv.lock \\\n    uv sync --locked --no-install-project\n</code></pre> <p>Potential issues: - Docker doesn't track bind-mounted files - Layer might stay cached even when dependencies change - Requires careful hybrid strategies (COPY some, bind others) - More complex to understand and debug</p>"},{"location":"base-infra/dockerfile-strategy/#our-philosophy-explicit-over-implicit","title":"Our Philosophy: Explicit Over Implicit","text":"<p>Dependency changes SHOULD trigger rebuilds: - \u2705 Clear signal that something material changed - \u2705 Validates that dependencies actually update - \u2705 Predictable Docker caching behavior - \u2705 Easy to understand and debug</p> <p>The \"penalty\" for this explicitness is negligible: - Version bump in pyproject.toml \u2192 rebuilds layer \u2192 cache mount makes it ~2-5s - The cache mount provides 90% of the performance benefit - Simplicity is worth more than saving 3 seconds</p>"},{"location":"base-infra/dockerfile-strategy/#benefits-of-copy-approach","title":"Benefits of COPY Approach","text":"<ul> <li>\u2705 Simple - Standard Docker pattern, easy to understand</li> <li>\u2705 Explicit - Cache invalidation happens when it should</li> <li>\u2705 Reliable - Dependencies always update correctly</li> <li>\u2705 Fast - Cache mount handles performance optimization</li> <li>\u2705 Maintainable - Less explanation needed, easier debugging</li> </ul>"},{"location":"base-infra/dockerfile-strategy/#performance-comparison","title":"Performance Comparison","text":"Approach Builder Size Runtime Size Rebuild Time (code change) Simplicity Notes Single-stage 500MB 500MB 2-5 minutes \u2705 Simple No separation, slow rebuilds Multi-stage + COPY (ours) ~500MB ~200MB 5-10 seconds \u2705 Simple Best balance of performance and clarity Multi-stage + bind mounts ~480MB ~200MB 5-10 seconds \u274c Complex Marginal savings, complex caching UV distroless base Won't work N/A N/A N/A No shell for build commands <p>Key insight: The multi-stage build and cache mount provide 95% of the optimization. Bind mounts add complexity for minimal additional benefit (~20MB, ~2-3s).</p>"},{"location":"base-infra/dockerfile-strategy/#summary","title":"Summary","text":"<p>Why our multi-stage COPY approach?</p> <ol> <li>We can't use distroless uv image as base \u2192 no shell to run build commands</li> <li>We still want official uv binary \u2192 copy it from distroless image into python:slim</li> <li>We separate build from runtime \u2192 smaller final image, faster rebuilds</li> <li>Layer caching optimization \u2192 dependencies cached separately from code</li> <li>Simple COPY over bind mounts \u2192 explicit, reliable, maintainable</li> </ol> <p>Key architectural decisions:</p> Component Approach Why <code>uv</code> binary Copy from distroless Get official binary without distroless constraints Base image <code>python:3.13-slim</code> Need shell + Python for build, minimal for runtime Build pattern Multi-stage 50% size reduction (discard build tools) Dependency caching Cache mount Persist packages across builds (~80% speedup) Dependency files COPY both Explicit cache invalidation, predictable, simple Code separation <code>--no-install-project</code> Dependencies (slow) separate from code (fast) Source copy Copy src/ only Documentation changes don't trigger code layer rebuild README file touch in RUN Optimization: README updates don't invalidate install layer <p>This gives us: - \u2705 Official uv binary (always latest) - \u2705 Full build capabilities (shell, Python, package manager) - \u2705 Minimal runtime image (~200MB vs ~500MB) - \u2705 Fast rebuilds (5-10s for code changes, ~2-5s for dependency changes with cache) - \u2705 Documentation updates don't trigger code/install layer rebuilds - \u2705 Reliable dependency updates (explicit cache invalidation) - \u2705 Simple and maintainable (standard Docker patterns) - \u2705 Maximum security (non-root, minimal attack surface)</p>"},{"location":"base-infra/dockerfile-strategy/#local-development","title":"Local Development","text":"<p>For local development workflow using Docker Compose (recommended), see Docker Compose Workflow Guide.</p> <p>For direct Docker builds without Compose: <pre><code>DOCKER_BUILDKIT=1 docker build -t your-agent-name:latest .\n</code></pre></p>"},{"location":"base-infra/dockerfile-strategy/#references","title":"References","text":""},{"location":"base-infra/dockerfile-strategy/#uv-documentation","title":"UV Documentation","text":"<ul> <li>UV Docker Integration Guide</li> <li>UV Docker Intermediate Layers (Bind Mounts)</li> <li>UV Documentation</li> </ul>"},{"location":"base-infra/dockerfile-strategy/#docker-documentation","title":"Docker Documentation","text":"<ul> <li>Docker Best Practices</li> <li>Docker Multi-Stage Builds</li> <li>Docker RUN Command Reference</li> <li>BuildKit Cache Mounts</li> <li>Docker Bind Mounts</li> </ul>"},{"location":"base-infra/dockerfile-strategy/#docker-compose","title":"Docker Compose","text":"<ul> <li>Docker Compose Workflow Guide - Local development workflow</li> <li>Docker Compose Watch Mode</li> </ul>"},{"location":"base-infra/environment-variables/","title":"Environment Variables","text":"<p>Complete reference for all environment variables used in this project.</p>"},{"location":"base-infra/environment-variables/#required-configuration","title":"Required Configuration","text":""},{"location":"base-infra/environment-variables/#google-cloud-vertex-ai-model-authentication","title":"Google Cloud Vertex AI Model Authentication","text":"<p>GOOGLE_GENAI_USE_VERTEXAI - When: Set before running locally or bootstrap - Value: <code>TRUE</code> - Purpose: Enables Vertex AI authentication for Gemini models</p> <p>GOOGLE_CLOUD_PROJECT - When: Set before running locally or bootstrap - Value: Your GCP project ID (e.g., <code>my-project-123</code>) - Purpose: Identifies the Google Cloud project for Vertex AI and other GCP services</p> <p>GOOGLE_CLOUD_LOCATION - When: Set before running locally or bootstrap - Value: GCP region (e.g., <code>us-central1</code>) - Purpose: Sets the region for Vertex AI model calls and resource deployment</p>"},{"location":"base-infra/environment-variables/#agent-identification","title":"Agent Identification","text":"<p>AGENT_NAME - When: Set before bootstrap (used for naming GCP resources) - Value: Unique identifier (e.g., <code>my-agent</code>) - Purpose: Identifies cloud resources, logs, and traces - Note: Used as base name for Terraform resources (<code>{agent_name}-{workspace}</code>)</p>"},{"location":"base-infra/environment-variables/#opentelemetry-configuration","title":"OpenTelemetry Configuration","text":"<p>OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT - When: Set before bootstrap - Options:   - <code>TRUE</code> - Capture full prompts and responses in traces   - <code>FALSE</code> - Capture metadata only (no message content) - Purpose: Controls LLM message content capture in OpenTelemetry traces - Reference: OpenTelemetry GenAI Instrumentation - Consideration: Set to <code>FALSE</code> if handling sensitive data</p>"},{"location":"base-infra/environment-variables/#cloud-resources-optional","title":"Cloud Resources (Optional)","text":"<p>Optional: Add these for production-consistent testing with durable persistence. Defaults to in-memory services if unset.</p>"},{"location":"base-infra/environment-variables/#session-and-memory-persistence","title":"Session and Memory Persistence","text":"<p>AGENT_ENGINE - When: Set AFTER first deployment for local development with persistent sessions - Value: Agent Engine resource name (e.g., <code>projects/123/locations/us-central1/reasoningEngines/456</code>) - Default: Unset (in-memory ephemeral sessions) - How to get: GitHub Actions job summary (<code>gh run view &lt;run-id&gt;</code> or Actions tab UI) OR GCP Console (Vertex AI \u2192 Agent Builder \u2192 Reasoning Engines) - Why: Enables session persistence across server restarts</p>"},{"location":"base-infra/environment-variables/#artifact-storage","title":"Artifact Storage","text":"<p>ARTIFACT_SERVICE_URI - When: Set AFTER first deployment for local development with artifact persistence - Value: GCS bucket URI (e.g., <code>gs://my-artifact-bucket</code>) - Default: Unset (in-memory ephemeral storage) - How to get: GitHub Actions job summary (<code>gh run view &lt;run-id&gt;</code> or Actions tab UI) OR GCP Console (Cloud Storage \u2192 Buckets) - Why: Enables artifact storage persistence</p>"},{"location":"base-infra/environment-variables/#optional-agent-runtime-configuration","title":"Optional: Agent Runtime Configuration","text":""},{"location":"base-infra/environment-variables/#logging","title":"Logging","text":"<p>LOG_LEVEL - Options: <code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code>, <code>CRITICAL</code> - Default: <code>INFO</code> - Purpose: Controls logging verbosity - Usage: <pre><code>LOG_LEVEL=DEBUG uv run server\n</code></pre></p>"},{"location":"base-infra/environment-variables/#opentelemetry","title":"OpenTelemetry","text":"<p>TELEMETRY_NAMESPACE - Default: <code>local</code> - Purpose: Groups traces and logs by developer or environment in Cloud Trace - Usage: Filter traces in Cloud Trace by namespace to isolate your local development traces - Example: <code>TELEMETRY_NAMESPACE=alice-local</code> - Note: Cloud Run deployments automatically set this to workspace name (<code>default</code>, <code>dev</code>, <code>stage</code>, <code>prod</code>)</p>"},{"location":"base-infra/environment-variables/#server-configuration","title":"Server Configuration","text":"<p>HOST - Default: <code>127.0.0.1</code> - Purpose: Server bind address - Note: <code>127.0.0.1</code> binds to localhost only (recommended for local development)</p> <p>PORT - Default: <code>8000</code> - Purpose: Server listening port - Note: Cloud Run always uses port 8000, Docker Compose maps to host port 8000</p>"},{"location":"base-infra/environment-variables/#agent-features","title":"Agent Features","text":"<p>SERVE_WEB_INTERFACE - Default: <code>FALSE</code> - Purpose: Enables ADK web UI at http://127.0.0.1:8000 - Options:   - <code>FALSE</code> - API-only mode   - <code>TRUE</code> - Enable web interface</p> <p>RELOAD_AGENTS - Default: <code>FALSE</code> - Purpose: Enable agent hot-reloading on file changes (development only) - WARNING: Set to <code>FALSE</code> in production (Cloud Run forces <code>FALSE</code>) - Usage: Automatically reload agent configuration when code changes during development</p>"},{"location":"base-infra/environment-variables/#cors-configuration","title":"CORS Configuration","text":"<p>ALLOW_ORIGINS - Default: <code>[\"http://127.0.0.1\", \"http://127.0.0.1:8000\"]</code> - Format: JSON array string - Purpose: Configure CORS allowed origins - Example: <code>ALLOW_ORIGINS='[\"https://your-domain.com\", \"http://127.0.0.1:3000\"]'</code></p>"},{"location":"base-infra/environment-variables/#model-configuration","title":"Model Configuration","text":"<p>ROOT_AGENT_MODEL - Default: <code>gemini-2.5-flash</code> - Options: Any Gemini model (e.g., <code>gemini-2.5-pro</code>, <code>gemini-2.0-flash-exp</code>) - Purpose: Override default root agent model - Usage: Test different Gemini models without code changes</p>"},{"location":"base-infra/environment-variables/#optional-advanced-features","title":"Optional: Advanced Features","text":"<p>ADK_SUPPRESS_EXPERIMENTAL_FEATURE_WARNINGS - Default: <code>FALSE</code> - Purpose: Suppress ADK experimental feature warnings - Options:   - <code>FALSE</code> - Show warnings   - <code>TRUE</code> - Suppress warnings</p>"},{"location":"base-infra/environment-variables/#environment-variable-precedence","title":"Environment Variable Precedence","text":"<ol> <li>Environment variables (highest priority)</li> <li>.env file (loaded via <code>python-dotenv</code>)</li> <li>Default values (defined in code)</li> </ol>"},{"location":"base-infra/environment-variables/#security-best-practices","title":"Security Best Practices","text":"<ul> <li>Never commit <code>.env</code> files - Already gitignored</li> <li>Use Workload Identity Federation - No service account keys needed for CI/CD</li> <li>Rotate credentials - If <code>.env</code> is accidentally committed, rotate all credentials</li> <li>Limit OTEL content capture - Set <code>OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT=FALSE</code> for sensitive data</li> </ul>"},{"location":"base-infra/environment-variables/#reference","title":"Reference","text":"<p>See <code>.env.example</code> for a template configuration with inline comments.</p>"},{"location":"base-infra/observability/","title":"Agent Observability with OpenTelemetry","text":"<p>This project includes production-ready OpenTelemetry observability that provides consistent behavior across local development and deployed environments. The implementation automatically instruments LLM calls and application logs with minimal configuration while coexisting with ADK's internal telemetry infrastructure.</p>"},{"location":"base-infra/observability/#whats-instrumented","title":"What's Instrumented","text":"<ul> <li>LLM Operations: Google Generative AI SDK calls with request/response details</li> <li>Structured Logging: JSON logs with automatic trace correlation for Google Cloud Logging</li> <li>Agent Callbacks: Lifecycle logging for agent start/end, model calls, and tool invocations</li> </ul>"},{"location":"base-infra/observability/#key-features","title":"Key Features","text":"<ul> <li>Consistent Setup: Single <code>setup_opentelemetry()</code> function used across all environments (local and deployed)</li> <li>Instance-Level Tracking: Unique <code>SERVICE_INSTANCE_ID</code> per process (PID + UUID) for collision-free identification</li> <li>Environment Grouping: <code>SERVICE_NAMESPACE</code> automatically set to Terraform workspace in deployed environments (<code>default</code>, <code>dev</code>, <code>stage</code>, <code>prod</code>)</li> <li>Version Tracking: <code>SERVICE_VERSION</code> set to Cloud Run revision ID for deployment correlation</li> <li>Google Cloud Integration: Direct export to Google Cloud Trace (OTLP) and Cloud Logging</li> <li>Trace Correlation: Logs automatically include trace context via <code>LoggingInstrumentor</code></li> <li>Service Identification: OpenTelemetry <code>service.name</code> set to <code>AGENT_NAME</code> environment variable</li> <li>Authentication: Uses Application Default Credentials (ADC) for Google Cloud APIs</li> </ul>"},{"location":"base-infra/observability/#configuration","title":"Configuration","text":"<p>Required environment variables: - <code>AGENT_NAME</code>: OpenTelemetry service identifier (required) - <code>GOOGLE_CLOUD_PROJECT</code>: GCP project ID for trace and log export (required) - <code>OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT</code>: Capture LLM message content - <code>TRUE</code> or <code>FALSE</code> (required)</p> <p>Optional variables: - <code>GOOGLE_CLOUD_LOCATION</code>: Vertex AI region (default: <code>us-central1</code>) - <code>LOG_LEVEL</code>: Logging verbosity - <code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code>, <code>CRITICAL</code> (default: <code>INFO</code>) - <code>TELEMETRY_NAMESPACE</code>: Service namespace for trace grouping (default: <code>local</code>, auto-set to workspace in deployed environments)</p> <p>See <code>.env.example</code> for complete configuration reference.</p>"},{"location":"base-infra/observability/#usage","title":"Usage","text":"<p>Identical OpenTelemetry setup across local development and deployed environments: - Traces and logs automatically exported to Google Cloud - ADK web UI available locally (when <code>SERVE_WEB_INTERFACE=TRUE</code>) - Production tip: Set <code>LOG_LEVEL=INFO</code> to minimize logging costs</p>"},{"location":"base-infra/observability/#viewing-traces-and-logs","title":"Viewing Traces and Logs","text":""},{"location":"base-infra/observability/#google-cloud-console-recommended","title":"Google Cloud Console (Recommended)","text":"<p>Cloud Trace: Filter by <code>AGENT_NAME</code>, view spans, timing, and generative AI events</p> <p>Logs Explorer: Query <code>logName=\"projects/{PROJECT_ID}/logs/{AGENT_NAME}-otel-logs\"</code> for correlated logs</p>"},{"location":"base-infra/observability/#gcloud-cli","title":"gcloud CLI","text":"<pre><code># Tail logs in real-time\ngcloud logging tail \"resource.type=cloud_run_revision\" --format=json\n\n# Filter by log name\ngcloud logging tail \"logName:projects/{PROJECT_ID}/logs/{AGENT_NAME}-otel-logs\"\n\n# View recent traces\ngcloud trace list --limit=10\n</code></pre>"},{"location":"base-infra/observability/#vs-code-gcp-extension","title":"VS Code GCP Extension","text":"<p>Install the Google Cloud Code extension to view logs and traces directly in your IDE.</p>"},{"location":"base-infra/observability/#implementation-details","title":"Implementation Details","text":"<p>Functions: <code>configure_otel_resource()</code> sets resource attributes, <code>setup_opentelemetry()</code> configures exporters</p> <p>Components: <code>GoogleGenAiSdkInstrumentor</code> (LLM ops), <code>LoggingInstrumentor</code> (trace context), <code>CloudLoggingExporter</code> (logs), <code>OTLPSpanExporter</code> (traces)</p>"},{"location":"base-infra/observability/#resource-attributes","title":"Resource Attributes","text":"<p>OpenTelemetry resource attributes uniquely identify your service instances in traces and logs:</p> Attribute Source Example Description <code>service.name</code> <code>AGENT_NAME</code> env var <code>your-agent-name</code> Service identifier (set explicitly in <code>.env</code>) <code>service.namespace</code> <code>TELEMETRY_NAMESPACE</code> env var <code>default</code>/<code>dev</code>/<code>stage</code>/<code>prod</code> (deployed) or <code>local</code> (dev) Environment (via Terraform workspace) grouping for traces <code>service.version</code> <code>K_REVISION</code> env var <code>your-agent-name-00042-abc</code> (deployed) or <code>local</code> (dev) Cloud Run revision or local dev indicator <code>service.instance.id</code> Generated <code>worker-1234-a1b2c3d4e5f6</code> Unique process instance (PID + UUID) <code>gcp.project_id</code> <code>GOOGLE_CLOUD_PROJECT</code> env var <code>my-project-id</code> GCP project for resource correlation <p>Local Development: - <code>service.namespace</code>: Defaults to <code>\"local\"</code> (customize via <code>TELEMETRY_NAMESPACE</code> for multi-developer disambiguation) - <code>service.version</code>: Set to <code>\"local\"</code> - <code>service.instance.id</code>: Unique per server restart (includes UUID to prevent collisions)</p> <p>Deployed Environments: - <code>service.namespace</code>: Automatically set to Terraform workspace name (<code>default</code>, <code>dev</code>, <code>stage</code>, <code>prod</code>) - <code>service.version</code>: Automatically set to Cloud Run revision ID - <code>service.instance.id</code>: Unique per container instance</p>"},{"location":"base-infra/observability/#callback-logging","title":"Callback Logging","text":"<p><code>LoggingCallbacks</code> (in <code>callbacks.py</code>) logs agent lifecycle events (start/end, model calls, tool invocations) with automatic trace context correlation.</p>"},{"location":"base-infra/observability/#message-content-capture","title":"Message Content Capture","text":"<p><code>OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT</code> controls LLM content capture: - <code>TRUE</code>: Full content (debugging, higher costs, sensitive data) - <code>FALSE</code>: Metadata only (production, lower costs, privacy)</p> <p>[!IMPORTANT] Must be explicitly set to <code>TRUE</code> for ADK to capture conversation content</p>"},{"location":"base-infra/observability/#resources","title":"Resources","text":"<ul> <li>Vertex AI | Agent Engine | Trace an Agent</li> <li>Google Cloud Observability | Instrument ADK Applications with OpenTelemetry</li> <li>Google Cloud Trace | View Generative AI Events</li> <li>OpenTelemetry | Generative AI Instrumentation</li> <li>OpenTelemetry | Semantic Conventions for Generative AI</li> <li>OpenTelemetry Environment Variables</li> </ul>"},{"location":"base-infra/terraform-infrastructure/","title":"Terraform Infrastructure Guide","text":"<p>This guide explains the Terraform infrastructure setup for deploying the LLM agent to Google Cloud Platform.</p>"},{"location":"base-infra/terraform-infrastructure/#overview","title":"Overview","text":"<p>The project uses two Terraform modules with distinct responsibilities:</p> <ul> <li><code>terraform/bootstrap/</code> - One-time CI/CD infrastructure setup</li> <li>Workload Identity Federation for GitHub Actions</li> <li>Artifact Registry for Docker images</li> <li>GCS bucket for main module's Terraform state</li> <li>GitHub Actions Variables (auto-configured)</li> <li> <p>State management: Local state (default)</p> </li> <li> <p><code>terraform/main/</code> - Application deployment (runs in CI/CD)</p> </li> <li>Cloud Run service configuration</li> <li>Service account and IAM bindings</li> <li>Vertex AI Reasoning Engine for session/memory persistence</li> <li>GCS bucket for artifacts</li> <li>State management: Remote state in GCS (bucket created by bootstrap)</li> <li>Execution: Designed for GitHub Actions (local execution optional, see Advanced Usage)</li> </ul>"},{"location":"base-infra/terraform-infrastructure/#prerequisites","title":"Prerequisites","text":""},{"location":"base-infra/terraform-infrastructure/#1-required-tools","title":"1. Required Tools","text":"<ul> <li>Terraform &gt;= 1.14.0</li> <li>Google Cloud SDK (gcloud CLI)</li> <li>GitHub CLI (gh) - for GitHub Variables setup</li> </ul>"},{"location":"base-infra/terraform-infrastructure/#2-gcp-authentication","title":"2. GCP Authentication","text":"<p>Authenticate with Google Cloud:</p> <pre><code>gcloud auth application-default login\ngcloud config set project YOUR_PROJECT_ID\n</code></pre>"},{"location":"base-infra/terraform-infrastructure/#3-github-authentication","title":"3. GitHub Authentication","text":"<p>Authenticate with GitHub (for bootstrap module to create Variables):</p> <pre><code>gh auth login\n</code></pre>"},{"location":"base-infra/terraform-infrastructure/#4-environment-configuration","title":"4. Environment Configuration","text":"<p>Create <code>.env</code> from <code>.env.example</code> and configure required variables:</p> <pre><code>cp .env.example .env\n# Edit .env with your values\n</code></pre> <p>Required variables in <code>.env</code>: - <code>GOOGLE_CLOUD_PROJECT</code> - GCP project ID - <code>GOOGLE_CLOUD_LOCATION</code> - GCP region (e.g., <code>us-central1</code>) - <code>AGENT_NAME</code> - Your agent name (e.g., <code>your-agent-name</code>) - <code>OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT</code> - Capture LLM content in traces (TRUE/FALSE)</p> <p>Required variables in <code>terraform/bootstrap/terraform.tfvars</code>: - <code>repository_owner</code> - GitHub username or organization - <code>repository_name</code> - Repository name</p> <p>See Bootstrap Setup for detailed configuration steps.</p>"},{"location":"base-infra/terraform-infrastructure/#state-management","title":"State Management","text":""},{"location":"base-infra/terraform-infrastructure/#bootstrap-module-local-state","title":"Bootstrap Module - Local State","text":"<p>The bootstrap module uses local state by default because: - Bootstrap is a one-time operation that creates CI/CD infrastructure - Simpler setup (no chicken-egg problem with state buckets) - Local state file can be committed to version control if desired - Team collaboration can configure remote state if needed (see Advanced Usage)</p> <p>State location: <code>terraform/bootstrap/terraform.tfstate</code> (gitignored by default)</p>"},{"location":"base-infra/terraform-infrastructure/#main-module-remote-state-in-gcs","title":"Main Module - Remote State in GCS","text":"<p>The main module uses remote state in GCS because: - CI/CD requires shared state between workflow runs - State locking prevents concurrent modification conflicts - Versioning enables recovery from state corruption - GitHub Actions has automatic access via WIF</p> <p>State bucket: Created by bootstrap module, name follows pattern <code>terraform-state-{agent-name}-{random-suffix}</code></p> <p>State location: <code>gs://terraform-state-{agent-name}-{random-suffix}/main/</code></p>"},{"location":"base-infra/terraform-infrastructure/#bootstrap-module","title":"Bootstrap Module","text":""},{"location":"base-infra/terraform-infrastructure/#purpose","title":"Purpose","text":"<p>Creates one-time infrastructure that supports automated CI/CD deployment. Run this module once from your local machine to set up the deployment pipeline.</p>"},{"location":"base-infra/terraform-infrastructure/#resources-created","title":"Resources Created","text":"<ol> <li>Workload Identity Federation - GitHub OIDC provider with IAM bindings (see <code>terraform/bootstrap/main.tf</code> for roles)</li> <li>Artifact Registry - Docker repository with cleanup policies (keeps 5 recent, <code>buildcache</code> tag indefinite)</li> <li>GCS Bucket for Main Module State - Versioned bucket for remote state</li> <li>GitHub Actions Variables - Auto-configured (see CI/CD Guide for list)</li> </ol>"},{"location":"base-infra/terraform-infrastructure/#configuration","title":"Configuration","text":"<p>Bootstrap reads configuration from <code>.env</code> using the <code>dotenv</code> provider:</p> <pre><code># terraform/bootstrap uses dotenv provider\ndata \"dotenv\" \"config\" {\n  filename = \"${path.cwd}/.env\"\n}\n</code></pre> <p>Security: Dotenv provider version <code>1.2.9</code> is pinned. See Security: Dotenv Provider section below.</p>"},{"location":"base-infra/terraform-infrastructure/#usage","title":"Usage","text":""},{"location":"base-infra/terraform-infrastructure/#initialize","title":"Initialize","text":"<pre><code># Run from repository root using -chdir flag\nterraform -chdir=terraform/bootstrap init\n</code></pre>"},{"location":"base-infra/terraform-infrastructure/#plan-and-apply","title":"Plan and Apply","text":"<pre><code># Preview changes\nterraform -chdir=terraform/bootstrap plan\n\n# Apply changes (creates all CI/CD infrastructure)\nterraform -chdir=terraform/bootstrap apply\n</code></pre> <p>Bootstrap typically completes in 2-3 minutes and outputs: - Terraform state bucket name - WIF provider name - Registry URI - List of GitHub Variables created</p>"},{"location":"base-infra/terraform-infrastructure/#verify-github-variables","title":"Verify GitHub Variables","text":"<pre><code># List all repository variables\ngh variable list\n\n# Expected output:\n# ARTIFACT_REGISTRY_LOCATION     us-central1\n# ARTIFACT_REGISTRY_URI          us-central1-docker.pkg.dev/...\n# GCP_LOCATION                   us-central1\n# GCP_PROJECT_ID                 your-project-id\n# GCP_WORKLOAD_IDENTITY_PROVIDER projects/.../locations/global/...\n# IMAGE_NAME                     your-agent-name\n# TERRAFORM_STATE_BUCKET         terraform-state-your-agent-name-a1b2c3d4\n</code></pre>"},{"location":"base-infra/terraform-infrastructure/#security-dotenv-provider","title":"Security: Dotenv Provider","text":"<p>Bootstrap uses <code>germanbrew/dotenv@1.2.9</code> for <code>.env</code> file reading. Version is pinned in <code>terraform/bootstrap/terraform.tf</code>. Provider is local-only (bootstrap execution), not used in CI/CD.</p>"},{"location":"base-infra/terraform-infrastructure/#main-module","title":"Main Module","text":""},{"location":"base-infra/terraform-infrastructure/#purpose_1","title":"Purpose","text":"<p>Deploys the LLM agent application to Cloud Run. Designed to run in GitHub Actions CI/CD as part of the automated deployment pipeline.</p> <p>Execution model: - Primary: GitHub Actions (automated on merge to main) - Secondary: Local execution possible for infrastructure-only changes (see Advanced Usage)</p>"},{"location":"base-infra/terraform-infrastructure/#resources-created_1","title":"Resources Created","text":"<ol> <li>Service Account - Attached to Cloud Run with IAM roles (see <code>terraform/main/main.tf</code>)</li> <li>Vertex AI Reasoning Engine - Session/memory persistence (resource name passed via <code>AGENT_ENGINE</code>)</li> <li>GCS Bucket for Artifacts - Versioned storage for agent artifacts</li> <li>Cloud Run Service - HTTP/2 on port 8000, auto-scaling 0-100 instances, <code>RELOAD_AGENTS</code> hardcoded to FALSE</li> </ol>"},{"location":"base-infra/terraform-infrastructure/#environment-specific-configuration","title":"Environment-Specific Configuration","text":"<p>Resource naming: All GCP resources use <code>local.resource_name = \"${var.agent_name}-${terraform.workspace}\"</code> (e.g., <code>my-agent-dev</code>, <code>my-agent-prod</code>)</p> <p>Billing labels: Resources tagged with <code>application = var.agent_name</code> and <code>environment = terraform.workspace</code> for cost tracking</p> <p>Observability: Cloud Run services automatically receive <code>TELEMETRY_NAMESPACE = terraform.workspace</code> env var, appearing as <code>service.namespace</code> in traces/logs for environment filtering</p>"},{"location":"base-infra/terraform-infrastructure/#iam-and-permissions-model","title":"IAM and Permissions Model","text":"<p>Project-level IAM assumption: Dedicated GCP project per deployment. Service account has project-level roles for all resources.</p> <p>App service account roles: See <code>terraform/main/main.tf</code> for complete list (Vertex AI, logging, storage access).</p> <p>Storage access: Project-level storage roles grant access to buckets within the same project only. For external buckets in different projects, configure cross-project IAM separately.</p> <p>GitHub Actions WIF roles: See <code>terraform/bootstrap/main.tf</code> for complete list.</p>"},{"location":"base-infra/terraform-infrastructure/#configuration_1","title":"Configuration","text":"<p>Main module receives all inputs via Terraform variables. No <code>.env</code> file reading.</p> <p>In GitHub Actions (via <code>terraform-plan-apply.yml</code> workflow): <pre><code>env:\n  TF_VAR_project: ${{ vars.GCP_PROJECT_ID }}\n  TF_VAR_location: ${{ vars.GCP_LOCATION }}\n  TF_VAR_agent_name: ${{ vars.IMAGE_NAME }}\n  TF_VAR_terraform_state_bucket: ${{ vars.TERRAFORM_STATE_BUCKET }}\n  TF_VAR_docker_image: ${{ inputs.docker_image }}\n</code></pre></p> <p>Backend configuration (bucket name): <pre><code># In GitHub Actions\nterraform init -backend-config=\"bucket=${{ vars.TERRAFORM_STATE_BUCKET }}\"\n</code></pre></p> <p>Variable details: - Required: <code>project</code>, <code>location</code>, <code>agent_name</code>, <code>terraform_state_bucket</code>, <code>docker_image</code> - Optional with defaults: <code>log_level</code> (INFO), <code>serve_web_interface</code> (false), <code>root_agent_model</code> (gemini-2.5-flash) - Nullable with defaults: <code>agent_engine</code> (uses created resource), <code>artifact_service_uri</code> (uses created bucket)</p>"},{"location":"base-infra/terraform-infrastructure/#terraform-variable-overrides","title":"Terraform Variable Overrides","text":"<p>The main module accepts optional runtime configuration variables that can be set via GitHub Actions Variables.</p> <p>How it works: 1. GitHub Actions Variables are set in the repository (e.g., <code>LOG_LEVEL=DEBUG</code>) 2. CI/CD workflow maps them to <code>TF_VAR_*</code> environment variables 3. Terraform uses <code>coalesce()</code> to fall back to defaults if null or empty</p> <p>Empty string handling: - GitHub Actions defaults unset Variables to empty strings (<code>\"\"</code>) - <code>coalesce(var.x, \"default\")</code> applies defaults when null or empty</p> <p>Available overrides: - <code>ADK_SUPPRESS_EXPERIMENTAL_FEATURE_WARNINGS</code> (default: TRUE) - <code>AGENT_ENGINE</code> (default: auto-created Reasoning Engine) - <code>ALLOW_ORIGINS</code> (default: <code>[\"http://127.0.0.1\", \"http://127.0.0.1:8000\"]</code>) - <code>ARTIFACT_SERVICE_URI</code> (default: auto-created GCS bucket) - <code>LOG_LEVEL</code> (default: INFO) - <code>ROOT_AGENT_MODEL</code> (default: gemini-2.5-flash) - <code>SERVE_WEB_INTERFACE</code> (default: FALSE)</p> <p>See <code>.github/workflows/terraform-plan-apply.yml</code> for the complete mapping.</p>"},{"location":"base-infra/terraform-infrastructure/#usage-in-cicd","title":"Usage in CI/CD","text":"<p>Main module runs automatically in GitHub Actions. See CI/CD Workflow Guide for complete details.</p>"},{"location":"base-infra/terraform-infrastructure/#local-execution-not-recommended","title":"Local Execution (Not Recommended)","text":"<p>The main module is designed for GitHub Actions execution. Local execution is possible but not supported. All Terraform inputs must be provided via <code>TF_VAR_*</code> environment variables, and the backend bucket must be configured via <code>-backend-config</code> flag.</p> <p>Note: The <code>docker_image</code> variable is nullable and defaults to the previous deployment's image from remote state, allowing infrastructure-only updates without specifying an image URI.</p>"},{"location":"base-infra/terraform-infrastructure/#workspace-management","title":"Workspace Management","text":"<p>Workspaces provide environment isolation (default, dev, stage, prod).</p>"},{"location":"base-infra/terraform-infrastructure/#workspaces","title":"Workspaces","text":"<p>Bootstrap: Uses <code>default</code> workspace (workspaces not recommended for local state).</p> <p>Main: Uses workspaces for environment isolation in CI/CD (default/dev/stage/prod). Workspace selection happens automatically via the <code>--or-create</code> flag in workflows.</p> <pre><code># List workspaces\nterraform -chdir=terraform/main workspace list\n\n# Create workspace (manual)\nterraform -chdir=terraform/main workspace new stage\n</code></pre>"},{"location":"base-infra/terraform-infrastructure/#common-operations","title":"Common Operations","text":""},{"location":"base-infra/terraform-infrastructure/#view-outputs","title":"View Outputs","text":"<pre><code># Bootstrap outputs\nterraform -chdir=terraform/bootstrap output\nterraform -chdir=terraform/bootstrap output -raw terraform_state_bucket\n\n# Main outputs\nterraform -chdir=terraform/main output\nterraform -chdir=terraform/main output -json cloud_run_services\n</code></pre>"},{"location":"base-infra/terraform-infrastructure/#update-bootstrap","title":"Update Bootstrap","text":"<pre><code># After modifying .env or bootstrap/*.tf\nterraform -chdir=terraform/bootstrap plan\nterraform -chdir=terraform/bootstrap apply\n</code></pre>"},{"location":"base-infra/terraform-infrastructure/#inspect-state","title":"Inspect State","text":"<pre><code># List resources in state\nterraform -chdir=terraform/main state list\n\n# Show specific resource\nterraform -chdir=terraform/main state show google_vertex_ai_reasoning_engine.session_and_memory\n</code></pre>"},{"location":"base-infra/terraform-infrastructure/#troubleshooting","title":"Troubleshooting","text":""},{"location":"base-infra/terraform-infrastructure/#backend-initialization-fails","title":"Backend Initialization Fails","text":"<p>Error: <code>Backend configuration changed</code></p> <p>Solution: Reinitialize with <code>-reconfigure</code>:</p> <pre><code>terraform -chdir=terraform/main init -reconfigure \\\n  -backend-config=\"bucket=${STATE_BUCKET}\"\n</code></pre>"},{"location":"base-infra/terraform-infrastructure/#state-locking-errors","title":"State Locking Errors","text":"<p>Error: <code>Error acquiring the state lock</code></p> <p>Cause: Previous Terraform operation didn't complete cleanly.</p> <p>Solution: Force unlock (use with caution):</p> <pre><code># Get lock ID from error message\nterraform -chdir=terraform/main force-unlock LOCK_ID\n</code></pre>"},{"location":"base-infra/terraform-infrastructure/#github-variables-issues","title":"GitHub Variables Issues","text":"<p>For GitHub Variables troubleshooting, see CI/CD Workflow Guide.</p>"},{"location":"base-infra/terraform-infrastructure/#cicd-integration","title":"CI/CD Integration","text":"<p>The Terraform modules are designed for GitHub Actions automation:</p> <p>Bootstrap \u2192 GitHub Variables \u2192 Workflows</p> <pre><code>terraform/bootstrap\n  \u2193 (creates)\nGitHub Variables (GCP_PROJECT_ID, TERRAFORM_STATE_BUCKET, etc.)\n  \u2193 (used by)\n.github/workflows/terraform-plan-apply.yml\n  \u2193 (runs)\nterraform/main (with TF_VAR_* from Variables)\n</code></pre> <p>See CI/CD Workflow Guide for complete workflow details.</p>"},{"location":"base-infra/terraform-infrastructure/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"base-infra/terraform-infrastructure/#bootstrap-with-remote-state","title":"Bootstrap with Remote State","text":"<p>The bootstrap module uses local state by default. Remote state via GCS backend is possible by creating a <code>backend.tf</code> file, but this is not the recommended or supported configuration for this template.</p>"},{"location":"base-infra/terraform-infrastructure/#next-steps","title":"Next Steps","text":"<ol> <li>\u2705 Configure <code>.env</code> file</li> <li>\u2705 Run bootstrap module (creates CI/CD infrastructure)</li> <li>\u2705 Verify GitHub Variables created</li> <li>\ud83d\udcd6 See CI/CD Workflow Guide for automated deployment</li> <li>\ud83d\udcd6 See Development Guide for local development</li> </ol>"},{"location":"base-infra/terraform-infrastructure/#design-rationale","title":"Design Rationale","text":"<p>Local state for bootstrap: - One-time operation that creates CI/CD infrastructure - No chicken-egg problem (no state bucket needed to create state bucket) - Simpler setup for template users</p> <p>TF_VAR_* in main module (no dotenv): - Standard Terraform pattern for CI/CD - No <code>.env</code> file exposure in workflows - Single execution environment to support</p> <p>Agent Engine in main (not bootstrap): - Lifecycle coupling with application deployment - Environment isolation via workspaces - No cross-module remote state dependencies</p> <p>Local development: Optionally copy Agent Engine resource name to <code>.env</code> after first deployment for persistent sessions in local development.</p>"},{"location":"base-infra/validating-multiplatform-builds/","title":"Validating Multi-Platform Docker Builds in Cloud Run","text":"<p>Multi-platform builds create a manifest list (index) and platform-specific images (amd64, arm64). Cloud Run deploys the manifest list but runs the platform-specific image, resulting in different digests in different places. This is expected.</p>"},{"location":"base-infra/validating-multiplatform-builds/#verification-script","title":"Verification Script","text":"<pre><code>#!/usr/bin/env bash\nset -euo pipefail\n\n# Configuration - Set these 4 variables\nPROJECT=\"your-gcp-project-id\"\nLOCATION=\"us-central1\"\nSERVICE_NAME=\"your-cloud-run-service-name\"\nVERSION_TAG=\"v0.4.1\"\n\necho \"=== Multi-Platform Build Validation ===\"\necho \"\"\n\n# Parse deployment details from Cloud Run\nDEPLOYED_IMAGE=$(gcloud run services describe $SERVICE_NAME \\\n  --region $LOCATION \\\n  --format='value(spec.template.spec.containers[0].image)')\n\nREGISTRY_URI=$(echo $DEPLOYED_IMAGE | cut -d'@' -f1)\nIMAGE_NAME=$(echo $REGISTRY_URI | awk -F'/' '{print $NF}')\nREPO=$(echo $REGISTRY_URI | awk -F'/' '{print $(NF-1)}')\n\nREVISION_NAME=$(gcloud run services describe $SERVICE_NAME \\\n  --region $LOCATION \\\n  --format='value(status.latestReadyRevisionName)')\n\necho \"Configuration:\"\necho \"  Service: $SERVICE_NAME\"\necho \"  Repository: $REPO\"\necho \"  Image: $IMAGE_NAME\"\necho \"  Revision: $REVISION_NAME\"\necho \"\"\n\n# Step 1: Get manifest list digest (deployed)\nMANIFEST_DIGEST_URI=$(gcloud run services describe $SERVICE_NAME \\\n  --region $LOCATION \\\n  --format='value(spec.template.spec.containers[0].image)')\nMANIFEST_DIGEST=$(echo $MANIFEST_DIGEST_URI | sed 's/.*@sha256://')\necho \"Manifest list digest: sha256:$MANIFEST_DIGEST\"\n\n# Step 2: Get platform-specific digest (running)\nPLATFORM_DIGEST_URI=$(gcloud run revisions describe $REVISION_NAME \\\n  --region $LOCATION \\\n  --format='value(spec.containers[0].image)')\nPLATFORM_DIGEST=$(echo $PLATFORM_DIGEST_URI | sed 's/.*@sha256://')\necho \"Platform digest:      sha256:$PLATFORM_DIGEST\"\necho \"\"\n\n# Step 3: Verify tag points to manifest list\nTAG_DIGEST_URI=$(gcloud artifacts docker images describe \\\n  \"${REGISTRY_URI}:${VERSION_TAG}\" \\\n  --format=\"value(image_summary.digest)\")\necho \"Tag $VERSION_TAG \u2192 $TAG_DIGEST_URI\"\n\nif [[ \"$TAG_DIGEST_URI\" == \"sha256:$MANIFEST_DIGEST\" ]]; then\n  echo \"  \u2713 Tag points to manifest list\"\nelse\n  echo \"  \u2717 Tag mismatch!\"\n  exit 1\nfi\n\n# Step 4: Verify manifest contains platform image\nCONTAINED_DIGEST=$(docker manifest inspect \\\n  \"${REGISTRY_URI}@sha256:${MANIFEST_DIGEST}\" \\\n  | jq -r '.manifests[] | select(.platform.architecture==\"amd64\") | .digest')\necho \"Manifest contains \u2192 $CONTAINED_DIGEST\"\n\nif [[ \"$CONTAINED_DIGEST\" == \"sha256:$PLATFORM_DIGEST\" ]]; then\n  echo \"  \u2713 Manifest contains platform image\"\nelse\n  echo \"  \u2717 Platform mismatch!\"\n  exit 1\nfi\n\necho \"\"\necho \"=== Validation Passed \u2713 ===\"\necho \"\"\necho \"Trace: Tag $VERSION_TAG \u2192 Manifest (${MANIFEST_DIGEST:0:12}...) \u2192 Platform (${PLATFORM_DIGEST:0:12}...)\"\n</code></pre>"},{"location":"base-infra/validating-multiplatform-builds/#setup","title":"Setup","text":"<p>Docker authentication (required for <code>docker manifest inspect</code>): <pre><code>gcloud auth configure-docker ${LOCATION}-docker.pkg.dev\n</code></pre></p>"},{"location":"base-infra/validating-multiplatform-builds/#related-docs","title":"Related Docs","text":"<ul> <li>CI/CD Workflow Guide</li> </ul>"}]}